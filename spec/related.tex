\section{Cloud Storage Synchronization Literature Search}
Ubiquitous digital technologies have the potential to capture knowledge about how we behave and about how the effect that the environment and the systems around us have on us. Key enabling technologies have emerged in the form of sensor networks that provide the capabilities to capture, store, transmit and analyse data about ourselves and the world. Such sensor networks have been used for various applications such as environmental monitoring, subject tracking, health care, and intelligent buildings.

Data management becomes crucial in ensuring that the correct lessons are learned from the mighty deluge of data that has emerged Sensors are able to generate a staggering amount of data and their provenance and storage must be ensured. Furthermore, we have not reached a stage of global network reliability. Instead, coverage is interspersed, systems go on and offline and latencies range from the practically non-existent to maddening delays.

Cloud computing, the provisioning of on-demand computing resources, may be able to help with the storage and computational analysis needs of researchers and industry. Their data are being generated at high frequencies from a multitude of devices that are deployed all about the us, or worn or carried by us. These data however, require entry into the cloud. 

This sensor-cloud connection is a problem worth considering. In some cases plain old data transfer solutions (PODTS) may be the best choice. Such users could simply collect sensor reading data into files on a device and direct it to periodically post the files to a data store using a well known protocol such as FTP. This is a viable solution when the users don't care about lost datapoints (perhaps owing to device or network failure), data tampering, data size, cache failure, or possibly even storage provider lock-in. Given these concerns PODTS is probably not appropriate for many situations and projects.

Considering data transfer from the local capture network to the cloud therefore motivates determining answers to these key issues:
\begin{itemize}
\item What options are available for transferring and storing data from local capture environments to the cloud? What are the tradeoffs for the various options?
\item What cloud storage options are available?
\item What existing architectures and system components have already been proposed for moving data into the cloud? What are their advantages and limitations, and is there room for improvement?
\item What methods exist for data security and privacy, both in terms of transfer and storage? When should such measures be taken? Is it possible to allow secure analysis of the data within the cloud? How should key management work within this context?
\item What metadata ought to be transmitted with the data? What standards are currently available? Are these standards sufficient and do they enable appropriate reasoning about the data and their provenance?
\item How do various Horizon projects currently handle these issues and what recommendations can be made to upgrade the projects to best practices?
\item How can we model or simulate sensor cloud integration in order to minimise deployment costs and problems?
\end{itemize}

The following literature review attempts to answer these questions by examining the academic and industrial state-of-the-art in sensor-cloud integration. This section begins with a review of general cloud computing and sensor network ideas and terminology then looks into specific sensor-cloud integration. The review began as an examination into cloud (and general file/data) synchronization options but has exposed various cloud gateway issues such as compression, security, metadata management, compression and external connection handling. The general method of research for this section involved the identification and search of key journals, conferences and industrial player white papers to find relevant high impact works and to critically analyse these to answer the above questions.

\subsection{Sensor Networks And Cloud Computing Defined}	
Sensor networks are a well-researched area of distributed computing. The design of them and their network dynamics have been well-studied and are, in most part, outside the scope of this survey. The curious reader is invited to review key surveys of sensor networks such as \cite{Akyildiz2002393}, \cite{1368897} and \cite{Yick20082292}. Of interest, though from sensor networks is the notion of sink nodes. These nodes tend to collect data from the other nodes and forward them on to base stations. For our purposes, we will consider such nodes to be gateways between the local data capture environment and the external storage and analysis environment. We will limit our survey to how these gateway nodes exchange information between the local environment and the external ones.

Cloud computing, the provisioning of on-demand computing resources,	has garnered a great deal of recent attention. Cloud computing shares charateristics with earlier distributed computing methods such as cluster computing and grid computing however there are unique features sepcific to it. Here, we follow the NIST definition of Cloud computing from \cite{Mell2011}:

``Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction.''

NIST describes three service models: Software as a Service (SaaS), Platform as a Service (PaaS) and Infrastructure as a Service (IaaS). For this survey, we are particularly interested in the data storage facet of Cloud computing. Cloud data storage can be provisioned using any of the service models. For instance, an IaaS solution might be hosting a NoSQL database solution on a series of Amazon EC2 compute nodes, a PaaS solution may be to use a storage web service such as Microsoft SQL Azure, and a SaaS solution may be to use an online solution such as Dropbox.

Cloud storage, according to \cite{armbrust2009above} is likely to become a dominant sensor storage solution because of the potential convenience it offers to data set collectors and users. Cloud storage offers the appearance of infinite on-demand capacity as the provisioning of services to process, analyse and mashup data. They also pointed out, however, key obstacles that must be overcome to realise the vision of cloud storage. Chief amongst these are 	service availability, service provider lock-in, data confidentiality issues, and data transfer bottlenecks and costs. These issues are addressed throughout this document. \cite{Connor2011} provides an IT industry high-level overview of cloud storage and is a good primer regarding existing storage APIs and requirements. 			

According to \cite{4812386} different categories of data storage applications have relative likelihoods of using cloud for storage. They posit that transactional mission critical data will remain out of the cloud owing to potential security or privacy attacks on the data. On the other hand they believe that cloud storage is well-suited to 
analytical and business intelligence data. A key ingredient for success according to them will be being able to operate on encrypted data (which is considered in greater detail below in the section on data security).

We will return to cloud storage options further down in this survey, but first we must survey the current state of connecting sensors and the cloud.

\subsection{Sensor Cloud Integration}					
There has been relatively little attention given to integrating sensor networks with cloud computing compared with other topics in either domain. Of note however are the works of \cite{briefingscan}, \cite{hassan2009framework}, \cite{melchor2011design}, \cite{Stuedi:2010:WLD:1810931.1810932}, \cite{5678063}, \cite{s111211581}, \cite{Patil2011}.

A system model and architecture for sensor network cloud integration is proposed in \cite{briefingscan}. Each sensor in their system is programmed individually to send data to a gateway node running in the cloud. The gateway receives raw bytes from the sensor network and enques them as packets. It also provides capabilities to reprogram nodes. A storage manager module processes and archives the sensor data. There are also interfaces for data consumption. Unfortunately, the paper is extremely high level and no further details were given of these components, nor were any test results provided.

A key motivating factor for existing sensor-cloud integration works has been immediate response to sensor readings. Such works however, tend to neglect long-term storage of the readings. While immediate reaction is important (such as for emergency response), long-term storage also has value. For instance, it is important to be able to review long-term changes to sensor readings in a building in order to best maintain it. An integration framework for connecting sensor networks to cloud applications was proposed in \cite{hassan2009framework}. They chiefly focused on determining events from the data and using a pub/sub model to inform clients of the given events. In their framework sensors pass data to gateway nodes that transmit them to a pub/sub broker. A policy engine controls how data is analysed. While this work provides a good starting architecture for responding to immediate sensor events, it does not discuss how data can be stored within the cloud however, brief mention is given to this problem in some follwo up work in \cite{5421618} where they mention (but provide no details about) storing data in a database local to the cloud gateway. They also provide a diagram that includes a "cloud db" object, but provide no information about this. Additional follow on work was reported about wireless sensors transmit data to cloud resources in \cite{s111211581} in order to build healthcare services. For this work a cloud gateway was deployed in the home of a patient and attached to a router. The data were then transmitted to servers running in the cloud. Unfortunaltey, to explain how this was done, they simply refered back to the previous work. The work in \cite{melchor2011design} was also motivated by immediate response and they showed how to provide immediate sensor data to in cloud data analysis jobs. In their architecture the gateway node (known as the sensor server) maintains an FTP server delivering data stored on each sensor that responds to pull requests. Such a solution is somewhat unsatisfactory however, because it is possible for data loss to occur resulting from limited sensor storage resources.

Another motivating factor for existing sensor-cloud integration works has been the opposite problem to the one that is under examination here, which is how to fetch data from the cloud and cache it on local devices. Such works are worth considering because they integrate cloud and local environments. In the work presented in \cite{Stuedi:2010:WLD:1810931.1810932} smart phone data caches are synchronised with cloud storage. Cache synchronisation was handled using the Cimbiosys pull-orientated platform for replication \cite{Ramasubramanian09cimbiosys:a}. Such pull-orientated solutions, however, are undesireable owing to the potential for data loss as discussed above.
						
Integrating sensor monitoring and modeling applications was the focus of \cite{5678063}. They noted that sensor networks data analysis and modeling has tended to be ad hoc. In their architecture the gateway is used to send sensor data to sensor network models that run in the cloud. Unfortunately, no details are provided regarding how the data are transferred, nor about problems regarding load or connection failure handling.

The work in \cite{Patil2011} points out the benefits of sensor network cloud integration: data storage and computation scalability as well as world-wide resource access. Their system, Intortus, interfaces with sensor netowrk gateways to securely store data and make the data available to other applications. In this architecture gateways receive sensor data and dispatch them as XML messages using web services to data storage services running on Google App Engine. Data are encrypted using AES-128 before transmission to the client and decrypted by clients when data are requested. This work does not, however, address issues to do with connectivity, using data in the cloud (besides for backup), handling multiple cloud storage vendors, metadta descriptions, or sensor network cloud simulation.

Although not directly related to sensor network cloud integration, the work in \cite{5961767} is of interest because they suggest an approach that integrates the local environment with the cloud. They were concerned by great latencies in opperation for home environments reliant on cloud services that could become disconnected from the Internet. Their solution, called VStore++ monitors resource availability in the local and external environement and directs services to them. This approach has some beneficial characteristics, however, would probably be overkill for most sensor networkds whose main tasks will be to simply collect data from devices.

The work presented in \cite{5948614} 
			Towards Reliable, Performant Workflows for Streaming-Applications on Cloud Platforms
			*** The following notes are direct copies of text (unless prefaced by ***):
				- propose and present a scientific workflow framework that supports streams as first-class data, and is optimized for performant and reliable execution across desktop and Cloud platforms
				- combine streaming data arriving from sensors with historic data available in file archives along with structured collections of weather forecast data that help the large scale computational model make an energy use prediction in near real time
				- workflow architecture that natively supports the three common data models found in science and engineering applications -- files, structured collections and data streams -- with the ability to seamlessly transition from one data model to another
				- logical stream abstractions have to be more robust than simple TCP sockets, given the unreliability and opaqueness introduced by operating in a distributed environment across desktop and Cloud with different characteristics from a typical local area network. Reliability of VMs hosting workflow tasks
is another concern to be addressed. Too, there has to be intelligence to avoid costly (both in time and money) duplicate movement of the same logical stream
				- Streams are a continuous series of binary data
				- transient unless mapped to another data model
				- In the future, Cloud providers may provide such streams as IaaS abstraction
				- registry service that maintains a list of known streams and the endpoints where particular
streams are provided
				- fault resistance: (1) transient or permanent loss of physical network, and (2) loss of virtual machines in the Cloud or services running on them.
			
			Efficient Sotrage Retrival and indexing of time seriies data
	
	sensor web	
		Semantic Sensor Web
		New Generation Sensor Web Enablement
		OGC Sensor Web Enablement Overview and High Level Architecture
		Semantic Sensor Observation Service
		Semantically-Enabled Sensor Plug \& Play for the Sensor Web
		The SID Creator A Visual Approach for Integrating Sensors with the Sensor Web
				
	Cloud experiences
			Adaptive Rate Stream Processing for Smart Grid Applications on Clouds
				- adaptive rate control to throttle the rate of generation of power events by smart meters, which meets accuracy requirements of smart grid applications while consuming 50\% lesser bandwidth resources in the Cloud
				- power events generated at a peak rate of 1 KB/min from 1.4 M consumers in the Los Angeles Smart Grid will require 2 TB/day of streaming data to be processed and analyzed at an average cumulative bandwidth of ~200Mbps
				- need for an adaptive stream rate control mechanism for generating power usage events
				- use the difference between the available power capacity at the utility and the current cumulative power usage by the consumers as our throttle function
				- disadvantages of static publishing rate:
					- setting too high a rate at which power events are published will cause excess resources (bandwidth, compute VMs for stream processing) to be utilized
					- setting too low a static rate at which power events are published can cause the utility to miss detecting a breach of a power usage threshold during peak load periods
				- adaptation logic (throttle)
					- as the total power usage within the utility approaches total available capacity, power usage events are required more frequently to detect/forecast a peak load event with low latency.
				- As future work, we plan to evaluate the scalability of the stream processing system with increasing number of VM instances, with the eventual goal of scaling up to 1.4 million smart meter streams that is expected in the Los Angeles Smart Grid. Both throughput and latency of the pipeline need to be measured as the stream rates adapt. Additional factors like availability of compute resources (\# of VMs), throughput of the stream processing system, and cost trade-off between Cloud resource usage and power conserved can be incorporated into the throttle policy.		
				
			Deploying Database Appliances in the Cloud
			
	Cloud Storage Gateway
		General resources
			wikipedia.org
				A cloud storage gateway is a network appliance or server which resides at the customer premises and translates cloud storage APIs such as SOAP or REST to block-based storage protocols such as iSCSI or Fibre Channel or file-based interfaces such as NFS or CIFS.
			
			CloudStorageSurvey--Avere
				- make cloud storage appear as local storage
				- translates cloud storage APIs to file interfaces or storage transport protocols
				- gateway resides at customer site
					- can be dedicated appliance/server, virtual appliance/server, or s/w application
						- features: compression, deduplication, encryption, caching, backup and recovery
				- Provides useful table columns for comparing cloud grteways, but unfortunately the table is incomplete (only the Avere FXT was examined and these cost \$50000+)	

			cloudStorage.pdf
			redundant cloud storage with octopus
			
			http://gladinet.blogspot.com/2010/09/how-to-pick-cloud-storage-gateway.html 
				- pick a cloud storage gateway, there are several questions:
					- 3 forms: s/w, virt. applicance, physical
					- which supported cloud storage providers
					- how to store data on cloud: 
						- block level
						- file level
					- what encryption/compression algo used
					
			http://www.cloudswitch.com/page/now-everybody-wants-a-cloud-gateway
				- gateway simplifies the integration and management of cloud resources so people can get on with using the cloud rather than struggling to make it work
				
			http://www.cloudswitch.com/blog/category/Cloud%20Gateway%20Series
				- a well-designed cloud gateway needs to:
					- guarantee security
					- gateway should allow users and administrators to monitor and manage applications running in a cloud as if they were running locally, using existing tools and polices in a single, integrated environment
					- protect roles and access
					
www.nasuni.com/blog/28dirtysecrets5weaknessesofcloudstorage  
				- gateway or device (virtual or physical) that needs to be installed at your site
				- beenfits:
					- improved performance
					- security
					- compression
					- dedup
					- WAN optimization
					- cache data
				- limitations
					- internet connection (can be mitigated usinga bulk data migration service)
					- Caches are not perfect and sometimes you will get read and write misses 
						- write miss: the space you need to write to in the cache is temporarily full and has not been freed up by offloading/sending data to the cloud
							-  ability to feed data to the appliance most likely is significantly faster than your Internet connection 
					- You can't get at your data without the appliance because the appliance adds a level of security
				- cloud storage gateways change the data written to them
					- compression, dedeup, encrypted, chunked for parallelism
					
			http://www.nasuni.com/blog/32blocksvsfileswhichapproachisbetterforcloud
				- block-based gateway
					- gateway works directly with blocks, the 512-byte fundamental units of storage
					- raw chunks of storage on a drive
					- Applications assume that blocks exist in local, fast storage
						- cloud: connections between the applications and the storage can become strained (latency issues)
					- Intelligent caching is really, really difficult 
					- Block-based gateways restore at the volume level, essentially restoring the blocks in a volume to a previous point in time
				- file-based gateway
					- Files provide a clear picture of the relationships among the blocks that support them
					- File-based gateways provide restore capabilities at the file, directory, or complete file system level
					- best for unstructured data
		Commercial offerings
			Ctera
				- cloud storage gateways that provides shared storage, cloud backup, folder synchronization and remote access in single devices
					- only uploads diffs/changed data
					- de-duplication
					- user bandwidth throttling (time based or constant)
					- 128-bit SSL
					- data encrypted using 256-bit AES \& fingerprinted by 160 bit SHA-1
					- Restore all or individual files
					- Rules-based CIFS, WebDAV and rsync based sync
					- FTP
					- Dashboard
						- Resource utilization
						- Event logs (system, access, backup, sync, audit)
						- Backup schedules
					- Email alerts
					- Automatic updates
					- Config backup/restore
				- rack mounted and plug form factors
				- remote centralised monitoring/management through a portal (SaaS or installed software)
			Nasuni
				- Nasuni Filer, a storage controller that runs in a datacenter as a hardware appliance or a virtual appliance
					- primary storage
					- built-in backup
					- offsite backup
					- all data and metadata is stored in the cache
					- cache snapshots
						- each file is encrypted, compressed and backedup to the Nasuni Service
					- cache management removes rarely re-used docs to respect the cache capacity
				- portal provides
					- volume \& cache metrics
					- alerts/notifications
					- remote file accss
					- control file sharing in the network
					- restore from snapshot
			Citrix
			http://www.opensourcerack.com/2011/05/25/citrix-netscaler-cloud-gateway-a-product-tour/
				- gateway to provision application access to users by administrators
			Gladinet 
				- Windows clients
				- Cloud server (http://gladinet.blogspot.com/2011/10/introducing-gladinet-cloud-server.html)
					- on premise gateway
					- file server that allows you to mount different cloud storage services such as Amazon S3 (default), Windows Azure, Google Storage, EMC Atmos into a Windows File Server
					- Map Drive to the Attached Cloud Storage Folder
					- Cache 
					- Connected to account
					- Mount service accounts (such as Amazon S3)
					- Active directory integration
				- Cloud for teams service
			Atmos 
				http://www.emc.com/collateral/software/white-papers/h9505-emc-atmos-archit-wp.pdf
				- store, manage, and protect globally distributed, unstructured content at scale
				Intel cloud builders guide
				http://www.emc.com/collateral/software/data-sheet/h5770-atmos-ds.pdf
		Open
			http://openstack.org/
				- backend oriented (S3 competitor)
			Nimbus Project
				https://github.com/nimbusproject/nimbus
				http://www.nimbusproject.org	
					- cloud computing for science
					- allows a client to lease remote resources by deploying virtual machines (VMs) on those resources and configuring them to represent an environment desired by the user					
				Cumulus
					Cumulus: an open source storage cloud for science
						- storage cloud implementation
						- compatible with the Amazon Web Services S3 REST API
						- quota management
						- used against many existing clients (boto, s3cmd, jets3t, etc)
						- open source implementation of the Amazon S3 REST AP
						- configure Cumulus with existing systems such as GPFS, PVFS and HDFS, in order to provide the desired reliability, availability or performance trade-offs
						- upload data to the cloud, monitor its status, and download it from the storage cloud as needed.
						- provides an image store for Nimbus compute clouds
						- S3 interface allows clients to write, read, and delete objects or organize them into buckets
						- Authentication mechanisms, based on request signature by symmetric key
						- authorization database
						- Redirection module used to handle scalability
						- implemented in python
						- the concept of a storage cloud is a fusion between data transfer and storage management
			Eucalyptus
				http://www.cca08.org/papers/Paper32-Daniel-Nurmi.pdf		
					- opensource software framework for cloud computing that implements IaaS
			
			JetS3t
				http://jets3t.s3.amazonaws.com/index.html
				- free, open-source Java toolkit and application suite for Amazon Simple Storage Service (Amazon S3), Amazon CloudFront content delivery network, and Google Storage for Developers
				- 5 applications:
					- Cockpit: graphical application for transferring files, viewing and managing the contents of an Amazon S3 or Google Storage account
					- Synchronize: command-line application for synchronizing directories on your computer with an Amazon S3 or Google Storage account
						- Files are copied to/from the Amazon S3 or Google Storage service
						- by default, only new or changed files are transferred
						- synchronize.properties file
							- accesskey and secretkey which define AWS access credentials
							- upload.max-part-size
								- files larger than this value will be split into smaller parts no larger than the value and uploaded as Multipart Uploads
							- upload.ignoreMissingPaths
								- Synchronize will perform an upload despite missing or unreadable source files
							- files can be gzipped or encrypted during synchronization
							- upload.metadata
								-  Custom metadata to apply when uploading new files to S3
						- no action option to generate a report of what will happen
						- force sync when files are up-to-date
					- Gatekeeper: servlet that acts as an authorization service running on a Service Provider's server to mediate access to S3 accounts
					- CockpitLite: graphical application that Service Providers with S3 accounts may provide to clients or customers without S3 accounts
					- Uploader: graphical application that Service Providers with S3 accounts may provide to clients or customers without S3 accounts
					
		s3cmd
			http://s3tools.org/s3cmd
				- command line tool for uploading, retrieving and managing data in Amazon S3
				- conditional/unconditional transfer
				- http and https
				- GPG encryption
				
	Synchronization Tools
		General resources
			Synch comparison chart 
				en.wikipedia.org/wiki/Comparisonoffilesynchronizationsoftware
		
		Common synch tools
			rsync
				- invented by Andrew Tridgell
				- first announced on 19 June 1996.[1] Rsync 3.0 was released on 1 March 2008
				- requires an rsync server running rsync daemon
				- algorithm
					- synchronizes files and directories from one location to another while minimizing data transfer using delta encoding
					
				- application
					- standard Linux utility
					- ported to Windows (via Cygwin), Mac OS
					- rsync is capable of limiting the bandwidth consumed during a transfer
					- supports compression and decompression
					- SSH
				Efficient Algorithms for Sorting and sync
				
			DeltaCopy
				- open source Windows' wrapper of rsync		
				- GPL 3
				
			Unison
				- Open Source by Benjamin C. Pierce 
				- Mac, Windows, Linux
				http://www.stanford.edu/~pgbovine/unisonguide.htm
					- batch option
					- ssh
				What's in Unison
				File Synchronization with Unison
					- two-way rsync with a bit of revision control mixed in
					- uses the rsync algorithm to keep network traffic down and should be tunneled through SSH over untrusted networks
					- Unison is programmed in OCaml
				- Own tests
					- Unison will not sync a file currently being written to
					
			Synkron
				- written in C++ and uses the Qt4 libraries
				- GPL v2
				- multiplatform 
				- synchronising multiple folders at the same time
				- can sync subfolders
				- file exclusions maintained in a blacklist; filters
				- scheduler
				- restore files overwritten during sync
				
			DirSync Pro 
				- GPL3
				- Java (JRE 1.6.0 and higher.)
				- Bi-directional (Two way) and mono-directional (One way) synchronization mode
				- Option to synchonise subdirectories recursively
				- Synchronizes files/folders any file system
				- handling time-stamps
				- Schedule Engine
				- gui and create a command line and save it to a batch file
				- logging/reporting facilities
				- no encryption
				
		Open source online tools
			SparkleShare 
				- opensource alternative to Dropbox
				https://github.com/hbons/SparkleShare
				http://sparkleshare.org/
					- Sa collaboration and sharing tool 
					- linux, mac, android
					- Documents synchronised to all peers when changes are made
					- notifications when someone has made a change
					- have as many projects as you'd like
					- use as much space as you'd like
					- run on as many hosts as you'd like
					- uses the GIT system as its backbone
					- store files on own Git server (SSH), Gitub, Gitorious
				http://www.makeuseof.com/tag/sparkleshare-great-open-source-alternative-dropbox-linux-mac/
				
			dvcs-autosync
				http://gitorious.org/dvcs-autosync
				explanatory article: http://www.mayrhofer.eu.org/dvcs-autosync
					- open source replacement for Dropbox/Wuala/Box.net/etc
					- based on distributed version control systems (DVCS)
					- Git is is being tested most thoroughly as the backend storage, but other DVCS such as Mercurial are also supported
					- A single Python script monitors the configured directory for live changes, commits these changes to the DVCS (such as git) and synchronizes with other instances using XMPP messages
					- linux only (since it relies on inotify)
					
			Syncany
				- open-source dropbox alternative
				- encrypts the files locally
				- plug-in based storage system supporting FTP, Amazon S3, Google Storage, Rackspace Cloud Files, WebDAV, Picassa, Box.net
				- Currently immature (alpha not yet released -- Windows \& MAC versions are even further behind)
		
		
		Online services
			Windows only
				symform
				http://www.symform.com/resilient-storage-architecture.aspx
					Windows only
				LiveMesh 
					http://www.codeproject.com/Articles/37200/Cloud-Based-Source-Control-using-Live-Mesh-and-Git
			
			SpiderOak
				Free with limited functionality by Spideroak
				Mac, iPhone, iPad, Windows, Linux, Online, Android
				- zero-knowledge privacy approach 
				- SpiderOak operates its own hardware and data centers without outsourcing
				- backup, sync, share
				- SpiderOak keeps historical versions of every file
				- 2048 bit RSA and 256 bit AES
				- \$10/mo/100 GB
				
			Dropbox
				Free with limited functionality 
				Mac, iPhone, iPad, Windows, Linux, Online, Android, Blackberry
				- Dropbox transfers just the parts of a file that change
				- Very common
				- Manually set bandwidth limits
				- Sharing
				- \$10 / month/50GB; \$20 / month/100GB; 
				- Secure Sockets Layer (SSL) and AES-256 bit encryption
				
			Ubuntu One
				Free with limited functionality by Canonical Ltd. 
				Windows, Linux, Online, Android, iPhone
				\$3/mo/20GB
				- Ubuntu One's data storage is simply a set of publically accessible CouchDBs.
				
			SugarSync
				Free with limited functionality by SugarSync 
				Mac, iPhone, iPad, Windows, Win Mobile, Online, Android, S60, Blackberry
				- backup any folder
				- versioning
				-real-time upload of changes
				- no file size limits
				- business plans
				
			Wuala
				Free by LaCie 
				Mac, iPhone, iPad, Windows, Linux, Online, Android
				- encrypts the data on your computer before it is uploaded
				- sync across multiple computers
				- share
				- Business and personal licenses
					- Business: 100 GB for 5 users - Eur 279 /year
					
			CrashPlan
				Free with limited functionality by Code42 
				Mac, Windows, Linux, Online
				- plans per computer or per GB
				
			Box.net
				Free with limited functionality by Box.net
				iPhone, iPad, Windows, Online, Android, Blackberry
				- personal, business and enterprise pricing
					- business: \$15/user/month - 1TB; 2GB file limit
					- Enterprise: \$? unlimited storage; 2 GB file limit
				- file versioning
				- comments and discussions
				- tasks
				- full text search
			Syncplicity
				Free with limited functionality by Syncplicity
				Mac, iPhone, Windows, Online
				- personal edition: \$15/mo/50GB
				- Business edition: \$45/mo/unlimited storage
				- no file size limit
			TeamDrive
				Free by TeamDrive Systems GmbH 
				Mac, Windows, Linux, Online
				- store on their TeamDrive cloud, your own server, or WebDAV servers
				
			ZumoDrive
				Free with limited functionality by Zecter Inc.
				Mac, iPhone, iPad, Windows, Linux, Online, Android
				- 10 GB \$2.99 / month; 25 GB \$6.99 / month; 50 GB \$9.99 / month; 100 GB \$19.99 / month ; 200 GB \$37.99 / month ; 500 GB 	\$79.99 / month
				
			Tonido
				Free by CodeLathe 
				Mac, iPhone, iPad, Windows, Win Phone 7, Linux, Online, Android, Blackberry
				- personal cloud software
				- make files and media in that computer available anywhere 
				- remotely access or share your music, photos, calendar, files, and more from any computer or mobile phone
				- TonidoPlug
					- Connect your TonidoPlug to your router, then connect any external USB hard drive to your plug to access your files, music and media stored in that hard drive from anywhere via any browser.
			Minus
				Free by Minus Inc 
				Mac, iPhone, iPad, Windows, Win Phone 7, Linux, Online, Android, Android Tablet, Blackberry  
				- drag and drop
				
			Duplicati
				Open Source by Kenneth Skovhede, mortenmie, et al 
				Windows, Linux 
				- c\#
				LGPL
				- storing the initial copy and then differentials to go from the initial version to the current
				- works with a number of different backends, eg. FTP, WEBDAV and S3, Rackspace Cloud File
				- built-in AES-256 encryption and backups can be signed using GNU Privacy Guard
				- built-in scheduler
				command-line client
				
			Acid Rain
				Open Source
				Mac, Windows, Linux, Online 
				- uses Mercurial 
					- run own server or use a Mercurial hosting service
				- Acid Rain Server is a Linux distribution based on Open Suse 11.3
			Sharebox
				- immature (in development)
				- a filesystem that will synchronize arbitrary data between several machines
				- developed in c
				- storage through git-annex
			lipsync
				- a lightweight commandline service that securely syncronizes your data 
				- linux only (server and client)
				- openSSH
				- rSync-based
				
		Personal Cloud servers		
			Pogoplug
				- £40
				- S/w for PC, Mac, Linux, iPhone, iPad, Android
			Iomega
				ix2-200 and ix4-200d network storage devices

	(Distributed) File Systems
		General Resources
			Cloud-based synchronization of distributed file system hierarchies
		Systems
			HekaFS
			http://git.fedorahosted.org/git/?p=CloudFS.git 
			Coda
			GlusterFS
			RFS
				RFSa network file system for mobile devices and the cloud [102]
				addresses three main issues as follows: maintaining seamless connection between users and clouds, controlling cache consistency, and supporting data privacy
		WebDAV 
		FUSE		

	Cloud storage services
		general resources
			Cloud storage survey (unpub.)
			An automated approach to cloud storage service selection
			MetaStoragecamera-ready
			Cloud Storage: Adoption, Practice and Deployment
				- Best practices
					* Chosing a provider: redundancy, fail-over, versioning, data back-up, mgmt console, pricing
					* local storage as well as cloud?
		Providers
			Amazon S3
			Windows Azure
			ATandT Synaptic Storage
			Rackspace CloudFile
			Peer1 CloudOne
			Nirvanix
			Mezeo
			Google Storage
			traditional FTP
			WebDav server
			Pachube
				RESTful
				Environment, Datastream and Datapoint model
				Push and Pull capabilities with ``live'' and ``frozen'' status
				Supports HTTPS/SSL
				Authentication is handled using API keys.


	Database Replication
		Unstructured
			CouchDB
			MongoDB

	Weak connections
		weaklyconnectedusers
		Peer-to-peer Data Replication Meets Delay Tolerant Networking
	Deduplication
		Building a high-performance deduplication system
	
	Cloud data security
		Challenges in Secure Sensor-Cloud Computing
		Toward Securing Sensor Clouds
		http://gigaom.com/cloud/the-cloud-meets-the-law-where-wikileaks-went-wrong/
		Structured Encryption and Controlled Disclosure
		Computing Arbitrary Functions of Encrypted Data
		Every Cloud has An Encrypted Lining: The Effectiveness of Cryptography in Cloud Computing	
		Fully homomorphic encryption using ideal lattices
		Distributing data for secure database services
		Addressing cloud computing security issues
		Silverline toward data confidentiality in storage-intensive cloud applications
		[92] Energy-efficient incremental integrity for securing storage in mobile cloud computing
		Lightweight and Compromise Resilient Storage Outsourcing with Distributed Secure Accessibility in Mobile Cloud Computing
		[93] Authentication in the clouds: a framework and its application to mobile users				
		Every Cloud has An Encrypted Lining- The Effectiveness of Cryptography in Cloud Computing
		
	SN/Cloud simulation
		Avrora Scalable Sensor Network Simulation
		CloudSim2010
		simulating wireless sensor networks with omnet++